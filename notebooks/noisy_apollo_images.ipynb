{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from shutil import copyfile\n",
    "from multiprocessing import Pool\n",
    "from cv2 import imread\n",
    "from tqdm.notebook import tqdm as tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../split_delete/Mesh_overlay_train_error _delete.txt\", \"r\") as f:\n",
    "    train_delete = list(map(lambda x: x.strip(), f.readlines()))\n",
    "\n",
    "with open(\"../split_delete/Mesh_overlay_val_error_delete.txt\", \"r\") as f:\n",
    "    val_delete = list(map(lambda x: x.strip(), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "APOLLOSCAPE_PATH = \"/disks/hdd/ECCV2018_apollo/train/images/\"\n",
    "PKU_PATH = \"/disks/hdd/pku-autonomous-driving/train_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def extract_features(image_path, vector_size=32):\n",
    "    image = imread(image_path)[:, :, ::-1]\n",
    "    try:\n",
    "        # Using KAZE, cause SIFT, ORB and other was moved to additional module\n",
    "        # which is adding addtional pain during install\n",
    "        alg = cv2.KAZE_create()\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them. \n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print('Error: ', e)\n",
    "        return None\n",
    "\n",
    "    return dsc\n",
    "\n",
    "\n",
    "def worker(filename):\n",
    "    name = filename.split('/')[-1].lower()\n",
    "    return extract_features(filename)\n",
    "\n",
    "\n",
    "def batch_extractor(files, pickled_db_path=\"features.pck\", n_jobs=1):\n",
    "    with Pool(n_jobs) as pool:\n",
    "        res = list(tqdm_notebook(pool.imap(worker, files), total=len(files)))\n",
    "    \n",
    "    result = {filename: r for filename, r in zip(files, res)}\n",
    "    \n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickled_db_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929bc843e8b14d8091ff2080ab5c857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = [os.path.join(APOLLOSCAPE_PATH, p + \".jpg\") for p in train_delete + val_delete]\n",
    "files = [f for f in files if os.path.exists(f)]\n",
    "batch_extractor(files, \"apolloscape_features.pkl\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6716bb9aea144cd49829022b135c9404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = [os.path.join(PKU_PATH, p) for p in sorted(os.listdir(PKU_PATH))]\n",
    "batch_extractor(files, \"pku_train_features.pkl\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"apolloscape_features.pkl\", \"rb\") as f:\n",
    "    apolloscape_features = pickle.load(f)\n",
    "with open(\"pku_train_features.pkl\", \"rb\") as f:\n",
    "    pku_train_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 4262)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apolloscape_features), len(pku_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher(object):\n",
    "\n",
    "    def __init__(self, pickled_db_path=\"features.pck\"):\n",
    "        with open(pickled_db_path, \"rb\") as fp:\n",
    "            self.data = pickle.load(fp)\n",
    "        self.names = []\n",
    "        self.matrix = []\n",
    "        for k, v in self.data.items():\n",
    "            self.names.append(k)\n",
    "            self.matrix.append(v)\n",
    "        self.matrix = np.array(self.matrix)\n",
    "        self.names = np.array(self.names)\n",
    "\n",
    "    def cos_cdist(self, vector):\n",
    "        # getting cosine distance between search image and images database\n",
    "        v = vector.reshape(1, -1)\n",
    "        return distance.cdist(self.matrix, v, 'cosine').reshape(-1)\n",
    "\n",
    "    def match(self, features, topn=5):\n",
    "        img_distances = self.cos_cdist(features)\n",
    "        # getting top 5 records\n",
    "        nearest_ids = np.argsort(img_distances)[:topn].tolist()\n",
    "        nearest_img_paths = self.names[nearest_ids].tolist()\n",
    "\n",
    "        return nearest_img_paths, img_distances[nearest_ids].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Matcher(\"pku_train_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['/disks/hdd/ECCV2018_apollo/train/images/180114_024344459_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_024346629_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_024348519_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_024407578_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_024412238_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_024951111_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025010537_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025021967_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025027681_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025144097_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025247600_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025314534_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025324232_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_025852824_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180114_031152751_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054356331_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054504387_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054508607_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054512627_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054514367_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054515967_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054600184_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054607471_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_054637542_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_061236774_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180116_064411230_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070605794_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070608454_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070609784_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070613774_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070743850_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_070914794_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_071801729_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_071919792_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_071935431_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180118_072157569_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_030918734_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_030919823_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_030922968_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_031203821_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_031204837_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_031209536_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/180310_031213854_Camera_5.jpg', '/disks/hdd/ECCV2018_apollo/train/images/171206_075202050_Camera_5.jpg'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apolloscape_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/disks/hdd/pku-autonomous-driving/train_images/ID_7f535a8b7.jpg',\n",
       "  '/disks/hdd/pku-autonomous-driving/train_images/ID_4b29ca144.jpg',\n",
       "  '/disks/hdd/pku-autonomous-driving/train_images/ID_4ed3caa54.jpg',\n",
       "  '/disks/hdd/pku-autonomous-driving/train_images/ID_0e8575fa6.jpg',\n",
       "  '/disks/hdd/pku-autonomous-driving/train_images/ID_c2e4e24da.jpg'],\n",
       " [0.1287426513886315,\n",
       "  0.1738005998305403,\n",
       "  0.17760406191770894,\n",
       "  0.18615926373417235,\n",
       "  0.18617297686150935])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.match(apolloscape_features['/disks/hdd/ECCV2018_apollo/train/images/180310_031213854_Camera_5.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"similar\"\n",
    "for apollo_path, apollo_features in apolloscape_features.items():\n",
    "    name = os.path.basename(apollo_path)\n",
    "    path = os.path.join(BASE, name.split('.')[0])\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    copyfile(apollo_path, os.path.join(path, name))\n",
    "    \n",
    "    matches = m.match(apollo_features, 80)\n",
    "    for match in matches[0]:\n",
    "        name = os.path.basename(match)\n",
    "        copyfile(match, os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for orig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
